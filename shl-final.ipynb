{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97919,"databundleVersionId":11872932,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install Dependencies\n!pip install transformers torchaudio --quiet\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchaudio\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:35:43.754876Z","iopub.execute_input":"2025-05-04T16:35:43.755600Z","iopub.status.idle":"2025-05-04T16:35:46.866904Z","shell.execute_reply.started":"2025-05-04T16:35:43.755578Z","shell.execute_reply":"2025-05-04T16:35:46.865845Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Paths & constants\nDATA_PATH = '/kaggle/input/shl-intern-hiring-assessment/Dataset'\nAUDIO_PATH = f'{DATA_PATH}/audios'\nTRAIN_AUDIO_DIR = f'{AUDIO_PATH}/train'\nTEST_AUDIO_DIR = f'{AUDIO_PATH}/test'\nSAMPLE_RATE = 16000\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nBATCH_SIZE = 1\nEPOCHS = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:51:30.750913Z","iopub.execute_input":"2025-05-04T16:51:30.751194Z","iopub.status.idle":"2025-05-04T16:51:30.755421Z","shell.execute_reply.started":"2025-05-04T16:51:30.751173Z","shell.execute_reply":"2025-05-04T16:51:30.754641Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df = pd.read_csv(f'{DATA_PATH}/train.csv')\ntest_df = pd.read_csv(f'{DATA_PATH}/test.csv')\n\n# Split 80-20 for validation\ntrain_df_, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n\nprint(f\"Train: {len(train_df_)} | Val: {len(val_df)} | Test: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:51:32.062766Z","iopub.execute_input":"2025-05-04T16:51:32.063366Z","iopub.status.idle":"2025-05-04T16:51:32.079336Z","shell.execute_reply.started":"2025-05-04T16:51:32.063337Z","shell.execute_reply":"2025-05-04T16:51:32.078578Z"}},"outputs":[{"name":"stdout","text":"Train: 355 | Val: 89 | Test: 204\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# Preprocessing\ndef preprocess_audio(file_path, target_sr=SAMPLE_RATE):\n    waveform, sr = torchaudio.load(file_path)\n\n    # Stereo â†’ Mono\n    if waveform.shape[0] > 1:\n        waveform = waveform.mean(dim=0, keepdim=True)\n\n    # Silence trim\n    waveform, _ = torchaudio.transforms.Vad(sample_rate=sr)(waveform)\n\n    # Resample\n    if sr != target_sr:\n        waveform = torchaudio.transforms.Resample(sr, target_sr)(waveform)\n\n    # Normalize\n    waveform = waveform / waveform.abs().max()\n\n    return waveform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:51:36.588316Z","iopub.execute_input":"2025-05-04T16:51:36.588580Z","iopub.status.idle":"2025-05-04T16:51:36.593447Z","shell.execute_reply.started":"2025-05-04T16:51:36.588561Z","shell.execute_reply":"2025-05-04T16:51:36.592780Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Custom dataset\n\nclass GrammarDataset(Dataset):\n    def __init__(self, df, audio_dir, labels=True):\n        self.df = df\n        self.audio_dir = audio_dir\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        path = os.path.join(self.audio_dir, row['filename'])\n        waveform, sr = torchaudio.load(path)\n\n        # Mono\n        if waveform.shape[0] > 1:\n            waveform = waveform.mean(dim=0, keepdim=True)\n\n        # Normalize\n        waveform = waveform / waveform.abs().max()\n\n        # Resample\n        if sr != 16000:\n            waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(waveform)\n\n        if self.labels:\n            return waveform, torch.tensor(row['label'], dtype=torch.float32)\n        else:\n            return waveform, row['filename']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:51:39.156958Z","iopub.execute_input":"2025-05-04T16:51:39.157257Z","iopub.status.idle":"2025-05-04T16:51:39.163371Z","shell.execute_reply.started":"2025-05-04T16:51:39.157227Z","shell.execute_reply":"2025-05-04T16:51:39.162785Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Model with Frozen HuBERT + Trainable Head\n\nfrom transformers import HubertModel\n\nclass HuBERTRegressor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n        for p in self.backbone.parameters():\n            p.requires_grad = False\n\n        self.regressor = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n\n    def forward(self, x):  # x: [B, T]\n        with torch.no_grad():\n            feats = self.backbone(x).last_hidden_state  # [B, T', 768]\n            pooled = feats.mean(dim=1)  # [B, 768]\n        return self.regressor(pooled).squeeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:51:41.516683Z","iopub.execute_input":"2025-05-04T16:51:41.516985Z","iopub.status.idle":"2025-05-04T16:51:41.522481Z","shell.execute_reply.started":"2025-05-04T16:51:41.516961Z","shell.execute_reply":"2025-05-04T16:51:41.521798Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Training and Evaluation\n\ndef train_model(model, train_loader, val_loader, epochs=EPOCHS):\n    model.to(DEVICE)\n    optimizer = torch.optim.Adam(model.regressor.parameters(), lr=1e-3)\n    loss_fn = nn.MSELoss()\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            preds = model(inputs)\n            loss = loss_fn(preds, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch+1} - Loss: {total_loss / len(train_loader):.4f}\")\n\n        # Validation\n        model.eval()\n        preds, targets = [], []\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n                output = model(inputs)\n                preds.extend(output.cpu().numpy())\n                targets.extend(labels.cpu().numpy())\n\n        rmse = mean_squared_error(targets, preds, squared=False)\n        pearson = pearsonr(targets, preds)[0]\n        print(f\"ðŸ“‰ Val RMSE: {rmse:.4f} | Pearson: {pearson:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:51:44.460772Z","iopub.execute_input":"2025-05-04T16:51:44.461317Z","iopub.status.idle":"2025-05-04T16:51:44.467894Z","shell.execute_reply.started":"2025-05-04T16:51:44.461294Z","shell.execute_reply":"2025-05-04T16:51:44.467102Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n\ndef collate_fn_train_val(batch):\n    waveforms = [x[0].squeeze(0) for x in batch]  # shape: [T]\n    padded = pad_sequence(waveforms, batch_first=True)  # shape: [B, T]\n    labels = torch.tensor([x[1] for x in batch], dtype=torch.float32)\n    return padded, labels\n\ndef collate_fn_test(batch):\n    waveforms = [x[0].squeeze(0) for x in batch]  # shape: [T]\n    padded = pad_sequence(waveforms, batch_first=True)  # shape: [B, T]\n    filenames = [x[1] for x in batch]\n    return padded, filenames\n\n\ntrain_set = GrammarDataset(train_df_, TRAIN_AUDIO_DIR, labels=True)\nval_set = GrammarDataset(val_df, TRAIN_AUDIO_DIR, labels=True)\ntest_set = GrammarDataset(test_df, TEST_AUDIO_DIR, labels=False)\n\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_train_val)\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE, collate_fn=collate_fn_train_val)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, collate_fn=collate_fn_test)\n    \nmodel = HuBERTRegressor()\ntrain_model(model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:51:47.235696Z","iopub.execute_input":"2025-05-04T16:51:47.236514Z","iopub.status.idle":"2025-05-04T17:19:38.883429Z","shell.execute_reply.started":"2025-05-04T16:51:47.236487Z","shell.execute_reply":"2025-05-04T17:19:38.882653Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 355/355 [04:37<00:00,  1.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Loss: 2.0002\nðŸ“‰ Val RMSE: 0.9553 | Pearson: 0.6557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 355/355 [04:22<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Loss: 1.0071\nðŸ“‰ Val RMSE: 0.8806 | Pearson: 0.7074\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 355/355 [04:24<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Loss: 0.8017\nðŸ“‰ Val RMSE: 1.0041 | Pearson: 0.6915\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 355/355 [04:23<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Loss: 0.7919\nðŸ“‰ Val RMSE: 0.7916 | Pearson: 0.7422\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 355/355 [04:23<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Loss: 0.7627\nðŸ“‰ Val RMSE: 0.9664 | Pearson: 0.6504\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"\n# Define test dataset and loader (with proper collate_fn)\ntest_set = GrammarDataset(test_df, TEST_AUDIO_DIR, labels=False)\ntest_loader = DataLoader(test_set, batch_size=1, collate_fn=collate_fn_test)  # BATCH_SIZE = 1\n\n# Inference\nmodel.eval()\nall_preds, all_fnames = [], []\n\nwith torch.no_grad():\n    for inputs, fnames in test_loader:\n        inputs = inputs.to(DEVICE)  # shape: [1, T]\n        preds = model(inputs).cpu().numpy()\n        all_preds.extend(preds)\n        all_fnames.extend(fnames)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:21:22.737655Z","iopub.execute_input":"2025-05-04T17:21:22.738372Z","iopub.status.idle":"2025-05-04T17:23:48.520427Z","shell.execute_reply.started":"2025-05-04T17:21:22.738349Z","shell.execute_reply":"2025-05-04T17:23:48.519516Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"filename\": all_fnames,\n    \"label\": all_preds\n})\n\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:24:38.954121Z","iopub.execute_input":"2025-05-04T17:24:38.954825Z","iopub.status.idle":"2025-05-04T17:24:38.988060Z","shell.execute_reply.started":"2025-05-04T17:24:38.954800Z","shell.execute_reply":"2025-05-04T17:24:38.987515Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"         filename     label\n0   audio_804.wav  3.718309\n1  audio_1028.wav  2.745551\n2   audio_865.wav  3.728491\n3   audio_774.wav  3.355473\n4  audio_1138.wav  3.974254","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_804.wav</td>\n      <td>3.718309</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_1028.wav</td>\n      <td>2.745551</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_865.wav</td>\n      <td>3.728491</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_774.wav</td>\n      <td>3.355473</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_1138.wav</td>\n      <td>3.974254</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}